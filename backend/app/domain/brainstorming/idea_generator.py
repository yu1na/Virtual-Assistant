"""
ì•„ì´ë””ì–´ ìƒì„± ë„êµ¬ (Idea Generator)

ì „ì²´ í”Œë¡œìš°:
1. Q1: ëª©ì /ë„ë©”ì¸ ì…ë ¥ ("ì–´ë””ì— ì“¸ ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?")
2. Q2: LLM ê¸°ë°˜ ì›Œë°ì—… ì§ˆë¬¸ ìƒì„± (2-3ê°œ) + "ë„¤" ì…ë ¥ ëŒ€ê¸°
3. Q3: ììœ ì—°ìƒ ì…ë ¥ (20ì´ˆ ì œí•œ, 10ê°œ ë¯¸ë§Œ ì‹œ ì¬ì…ë ¥)
4. ì„ì‹œ RAG ì²˜ë¦¬:
   - Q3 ì„ë² ë”© ë° ì„ì‹œ ChromaDB ì €ì¥
   - Q1-Q3 ìœ ì‚¬ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
   - ì˜êµ¬ RAG (SCAMPER, Mind Mapping, Starbursting)ì™€ ê²°í•©
   - LLMìœ¼ë¡œ ì•„ì´ë””ì–´ 2-3ê°œ ìƒì„±
   - ê° ì•„ì´ë””ì–´ë³„ SWOT ë˜ëŠ” How Now Wow ë¶„ì„
5. ì‚­ì œ í™•ì¸ ("ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?") - "ë„¤" ì…ë ¥ ì‹œ ëª¨ë“  ì„ì‹œ ë°ì´í„° ì‚­ì œ
"""

import readline  # í•œê¸€ ì…ë ¥ ë°±ìŠ¤í˜ì´ìŠ¤ ë²„ê·¸ ìˆ˜ì •
import time
import signal
import sys
import asyncio
from pathlib import Path
from typing import List, Dict, Optional
from openai import OpenAI
from dotenv import load_dotenv
import os

from session_manager import SessionManager
from ephemeral_rag import EphemeralRAG
from domain_hints import get_domain_hint, format_hint_for_prompt
from search.naver_news import NaverNewsSearcher
from search.duckduckgo import DuckDuckGoSearcher
from search.naver_datalab import NaverDataLabSearcher

# ChromaDB import
import chromadb
from chromadb.config import Settings as ChromaSettings


class TimeoutException(Exception):
    """ì‹œê°„ ì´ˆê³¼ ì˜ˆì™¸"""
    pass


def timeout_handler(signum, frame):
    """ì‹œê°„ ì´ˆê³¼ í•¸ë“¤ëŸ¬"""
    raise TimeoutException()


class IdeaGenerator:
    """
    ì•„ì´ë””ì–´ ìƒì„± ë„êµ¬ ë©”ì¸ í´ë˜ìŠ¤
    
    Q1 â†’ Q2 â†’ Q3 â†’ ì•„ì´ë””ì–´ ìƒì„± â†’ ë¶„ì„ â†’ ì‚­ì œì˜ ì „ì²´ í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        load_dotenv()
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.llm_model = os.getenv("LLM_MODEL", "gpt-4o")
        self.embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-large")
        
        # ì„¸ì…˜ ë§¤ë‹ˆì €
        self.session_manager = SessionManager()
        
        # ì˜êµ¬ RAG (SCAMPER, Mind Mapping, Starbursting) ChromaDB ì´ˆê¸°í™”
        current_file = Path(__file__).resolve()
        module_dir = current_file.parent
        persist_directory = str(module_dir / "data" / "chroma")
        
        self.chroma_client = chromadb.PersistentClient(
            path=persist_directory,
            settings=ChromaSettings(anonymized_telemetry=False)
        )
        
        try:
            # ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸ í›„ ë¡œë“œ
            print(f"ğŸ” ChromaDB ê²½ë¡œ: {persist_directory}")
            print("ğŸ” list_collections() í˜¸ì¶œ ì¤‘...")
            collections = self.chroma_client.list_collections()
            print(f"ğŸ” ì»¬ë ‰ì…˜ ëª©ë¡: {collections}")
            collection_names = [c.name for c in collections]
            print(f"ğŸ” ì»¬ë ‰ì…˜ ì´ë¦„ë“¤: {collection_names}")
            
            if "brainstorming_techniques" in collection_names:
                print("ğŸ” get_collection() í˜¸ì¶œ ì¤‘...")
                self.permanent_collection = self.chroma_client.get_collection(
                    name="brainstorming_techniques"
                )
                print(f"âœ… ì˜êµ¬ RAG ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ ({self.permanent_collection.count()}ê°œ ë¬¸ì„œ)")
            else:
                print("âš ï¸  ì˜êµ¬ RAG ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                print("   chroma_loader.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                self.permanent_collection = None
        except Exception as e:
            import traceback
            print(f"âš ï¸  ì˜êµ¬ RAG ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   ìƒì„¸ ì—ëŸ¬:")
            traceback.print_exc()
            print("   chroma_loader.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            self.permanent_collection = None
        
        # í˜„ì¬ ì„¸ì…˜ ì •ë³´
        self.current_session_id = None
        self.ephemeral_rag = None
        
        print("âœ… ì•„ì´ë””ì–´ ìƒì„± ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # íŠ¸ë Œë“œ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” (optional)
        try:
            self.trend_searcher = NaverNewsSearcher()
            print("âœ… ë„¤ì´ë²„ íŠ¸ë Œë“œ ê²€ìƒ‰ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸  íŠ¸ë Œë“œ ê²€ìƒ‰ ì´ˆê¸°í™” ì‹¤íŒ¨ (ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
            self.trend_searcher = None
        
        # ë•ë•ê³  ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        try:
            self.duckduckgo_searcher = DuckDuckGoSearcher()
            print("âœ… DuckDuckGo íŠ¸ë Œë“œ ê²€ìƒ‰ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸  DuckDuckGo ì´ˆê¸°í™” ì‹¤íŒ¨ (ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
            self.duckduckgo_searcher = None
        
        # ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        try:
            self.datalab_searcher = NaverDataLabSearcher()
            print("âœ… ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸  ë„¤ì´ë²„ ë°ì´í„°ë© ì´ˆê¸°í™” ì‹¤íŒ¨ (ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
            self.datalab_searcher = None
    
    def start_new_session(self) -> str:
        self.current_session_id = self.session_manager.create_session()
        session = self.session_manager.get_session(self.current_session_id)
        self.ephemeral_rag = EphemeralRAG(session_id=self.current_session_id)
        
        print(f"\n{'='*60}")
        print(f"ğŸ¨ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ìƒì„± ì„¸ì…˜ ì‹œì‘")
        print(f"   ì„¸ì…˜ ID: {self.current_session_id}")
        print(f"{'='*60}\n")
        
        return self.current_session_id
    
    def q1_ask_purpose(self) -> str:
        print("ğŸ“‹ Q1: ì–´ë””ì— ì“¸ ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?")
        print("    (ì˜ˆ: ëª¨ë°”ì¼ ì•±, ë§ˆì¼€íŒ… ìº í˜ì¸, ì‹ ì œí’ˆ ê¸°íš ë“±)")
        
        purpose = input("\nğŸ’­ ì…ë ¥: ").strip()
        self.session_manager.update_session(self.current_session_id, {'q1_purpose': purpose})
        
        print(f"\nâœ… ëª©ì ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {purpose}\n")
        return purpose
    
    def fetch_trend_keywords(self, purpose: str) -> List[str]:
        all_keywords = []
        
        if self.trend_searcher:
            print("ğŸ” ë„¤ì´ë²„ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘...")
            try:
                naver_keywords = asyncio.run(self.trend_searcher.extract_trend_keywords(purpose, num_articles=5))
                if naver_keywords:
                    print(f"   âœ… ë„¤ì´ë²„: {len(naver_keywords)}ê°œ ë°œê²¬")
                    all_keywords.extend(naver_keywords)
            except Exception as e:
                print(f"   âš ï¸  ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        if self.duckduckgo_searcher:
            print("ğŸ” DuckDuckGo ê¸€ë¡œë²Œ íŠ¸ë Œë“œ ê²€ìƒ‰ ì¤‘...")
            try:
                ddg_keywords = asyncio.run(self.duckduckgo_searcher.extract_trend_keywords(purpose, num_articles=5))
                if ddg_keywords:
                    print(f"   âœ… DuckDuckGo: {len(ddg_keywords)}ê°œ ë°œê²¬")
                    all_keywords.extend(ddg_keywords)
            except Exception as e:
                print(f"   âš ï¸  DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        if self.datalab_searcher:
            print("ğŸ” ë„¤ì´ë²„ ë°ì´í„°ë© íŠ¸ë Œë“œ ê²€ìƒ‰ ì¤‘...")
            try:
                datalab_keywords = asyncio.run(self.datalab_searcher.extract_trend_keywords(purpose))
                if datalab_keywords:
                    print(f"   âœ… ë„¤ì´ë²„ ë°ì´í„°ë©: {len(datalab_keywords)}ê°œ ë°œê²¬")
                    all_keywords.extend(datalab_keywords)
            except Exception as e:
                print(f"   âš ï¸  ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        unique_keywords = list(dict.fromkeys(all_keywords))
        
        if unique_keywords:
            print(f"\nâœ… ì´ íŠ¸ë Œë“œ í‚¤ì›Œë“œ {len(unique_keywords)}ê°œ:")
            for kw in unique_keywords:
                print(f"   - {kw}")
        else:
            print("âš ï¸  íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        return unique_keywords
    
    def q2_generate_warmup(self, purpose: str) -> List[str]:
        print("ğŸ¤” Q2: ë¸Œë ˆì¸ìŠ¤í† ë° ì›Œë°ì—…")
        print("    LLMì´ ì›Œë°ì—… ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n")
        
        prompt = f"""ì‚¬ìš©ìê°€ "{purpose}"ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•˜ë ¤ê³  í•©ë‹ˆë‹¤.

**ëª©í‘œ**: ì‚¬ìš©ìì˜ ì§êµ°/ìƒí™©ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì›Œë°ì—… ì§ˆë¬¸ 2-3ê°œ ìƒì„±

1. ë¨¼ì € ëª©ì ì„ ë³´ê³  ì§êµ°ì„ ì¶”ë¡ í•˜ì„¸ìš” (ìœ íŠœë²„, íšŒì‚¬ì›, ì†Œìƒê³µì¸, ê°œë°œì, í•™ìƒ ë“±)
2. í•´ë‹¹ ì§êµ°ì´ ê³ ë¯¼í•  ë²•í•œ êµ¬ì²´ì  ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”

ê° ì§ˆë¬¸ì€ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ í•œ ì¤„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ê¸°íšìì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§êµ°ì— ë§ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=400
            )
            
            warmup_text = response.choices[0].message.content.strip()
            warmup_questions = []
            for line in warmup_text.split('\n'):
                line = line.strip()
                if line and (line[0].isdigit() or line.startswith('-') or line.startswith('â€¢')):
                    cleaned = line.lstrip('0123456789.-â€¢) ').strip()
                    if cleaned:
                        warmup_questions.append(cleaned)
            
            self.session_manager.update_session(self.current_session_id, {'q2_warmup': warmup_questions})
            
            print("ğŸ’¡ ì›Œë°ì—… ì§ˆë¬¸:\n")
            for i, question in enumerate(warmup_questions, 1):
                print(f"   {i}. {question}")
            
            return warmup_questions
            
        except Exception as e:
            print(f"âŒ ì›Œë°ì—… ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def q2_wait_for_confirmation(self) -> bool:
        import time as time_module
        time_module.sleep(0.1)
        try:
            import termios
            termios.tcflush(sys.stdin, termios.TCIFLUSH)
        except:
            pass
        
        print("\n")
        response = input("ì¤€ë¹„ê°€ ë˜ì…¨ë‹¤ë©´ 'ë„¤'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
        
        if response == "ë„¤":
            print("âœ… Q3ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤!\n")
            return True
        else:
            print("âš ï¸  'ë„¤'ë¥¼ ì…ë ¥í•´ì•¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.")
            return False
    
    def q3_free_association(self, time_limit: int = 30, min_items: int = 10, max_items: int = 20) -> List[str]:
        print("ğŸš€ Q3: ììœ ì—°ìƒ")
        print(f"    ì§€ê¸ˆë¶€í„° {time_limit}ì´ˆ ë™ì•ˆ ë– ì˜¤ë¥´ëŠ” ë¬´ì—‡ì´ë“  ììœ ë¡­ê²Œ ë§ì´ ì ì–´ì£¼ì„¸ìš”.")
        print(f"    ê° í•­ëª©ì€ ì—”í„°ë¡œ êµ¬ë¶„í•˜ì„¸ìš”. (ìµœì†Œ {min_items}ê°œ, ìµœëŒ€ {max_items}ê°œ)")
        print(f"\nâ±ï¸  ì…ë ¥ ì‹œì‘!\n")
        
        associations = []
        start_time = time.time()
        
        try:
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(time_limit)
            
            while len(associations) < max_items:
                try:
                    elapsed = int(time.time() - start_time)
                    remaining = time_limit - elapsed
                    
                    if remaining <= 0:
                        break
                    
                    item = input(f"[{remaining}ì´ˆ ë‚¨ìŒ, {len(associations)}/{max_items}ê°œ] ğŸ’­ ").strip()
                    if item:
                        associations.append(item)
                        if len(associations) >= max_items:
                            print(f"\nâœ… ìµœëŒ€ {max_items}ê°œ ì…ë ¥ ì™„ë£Œ! ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.")
                            break
                        
                except TimeoutException:
                    print("\nâ° ì‹œê°„ ì¢…ë£Œ!")
                    break
                except EOFError:
                    break
            
            signal.alarm(0)
            
        except Exception as e:
            print(f"\nâš ï¸  ì…ë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            signal.alarm(0)
        
        import time as time_module
        time_module.sleep(0.1)
        try:
            import termios
            termios.tcflush(sys.stdin, termios.TCIFLUSH)
        except:
            pass
        
        print(f"\nâœ… {len(associations)}ê°œ í•­ëª© ì…ë ¥ ì™„ë£Œ!")
        
        if len(associations) < min_items:
            print(f"\nâš ï¸  ìµœì†Œ {min_items}ê°œ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”! (í˜„ì¬: {len(associations)}ê°œ)")
            print(f"    {min_items - len(associations)}ê°œ ë” í•„ìš”í•©ë‹ˆë‹¤.\n")
            
            remaining_needed = min_items - len(associations)
            remaining_allowed = max_items - len(associations)
            print(f"ğŸ”„ ë‹¤ì‹œ {time_limit}ì´ˆ ë™ì•ˆ ì¶”ê°€ ì…ë ¥í•´ì£¼ì„¸ìš”! (ìµœì†Œ {remaining_needed}ê°œ ë”, ìµœëŒ€ {remaining_allowed}ê°œê¹Œì§€)\n")
            additional = self.q3_free_association_retry(time_limit, remaining_needed, remaining_allowed)
            associations.extend(additional)
        
        self.session_manager.update_session(self.current_session_id, {'q3_associations': associations})
        self.ephemeral_rag.add_associations(associations)
        
        print(f"\nâœ… ì´ {len(associations)}ê°œ í•­ëª©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
        return associations
    
    def q3_free_association_retry(self, time_limit: int, needed: int, max_allowed: int) -> List[str]:
        associations = []
        start_time = time.time()
        
        try:
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(time_limit)
            
            while len(associations) < max_allowed:
                try:
                    elapsed = int(time.time() - start_time)
                    remaining = time_limit - elapsed
                    
                    if remaining <= 0:
                        break
                    
                    if len(associations) < needed:
                        status = f"{needed - len(associations)}ê°œ ë” í•„ìš”"
                    else:
                        status = f"ì¶©ë¶„í•¨, ìµœëŒ€ {max_allowed - len(associations)}ê°œ ë” ê°€ëŠ¥"
                    
                    item = input(f"[{remaining}ì´ˆ ë‚¨ìŒ, {status}] ğŸ’­ ").strip()
                    if item:
                        associations.append(item)
                        if len(associations) >= max_allowed:
                            print(f"\nâœ… ìµœëŒ€ ê°œìˆ˜ ë„ë‹¬! ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.")
                            break
                        
                except TimeoutException:
                    print("\nâ° ì‹œê°„ ì¢…ë£Œ!")
                    break
                except EOFError:
                    break
            
            signal.alarm(0)
            
        except Exception as e:
            print(f"\nâš ï¸  ì…ë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            signal.alarm(0)
        
        import time as time_module
        time_module.sleep(0.1)
        try:
            import termios
            termios.tcflush(sys.stdin, termios.TCIFLUSH)
        except:
            pass
        
        return associations
    
    def _search_permanent_rag(self, query: str, n_results: int = 5) -> List[Dict]:
        if not self.permanent_collection:
            return []
        
        try:
            query_embedding = self.ephemeral_rag.embed_text(query)
            results = self.permanent_collection.query(query_embeddings=[query_embedding], n_results=n_results)
            
            techniques = []
            if results['documents'] and len(results['documents'][0]) > 0:
                for i in range(len(results['documents'][0])):
                    techniques.append({
                        'title': results['metadatas'][0][i].get('title', 'N/A'),
                        'content': results['documents'][0][i],
                        'chunk_id': results['metadatas'][0][i].get('chunk_id', 'N/A'),
                        'similarity': 1 - results['distances'][0][i] if results['distances'] else 0
                    })
            
            return techniques
            
        except Exception as e:
            print(f"âš ï¸  ì˜êµ¬ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def generate_ideas(self, purpose: str, keywords: List[Dict], top_k_techniques: int = 3, trend_keywords: List[str] = None) -> List[Dict]:
        print("ğŸ¨ ì•„ì´ë””ì–´ ìƒì„± ì¤‘...\n")
        
        techniques_results = self._search_permanent_rag(query=purpose, n_results=top_k_techniques)
        keyword_str = ", ".join([kw['keyword'] for kw in keywords[:7]])
        techniques_str = "\n\n".join([f"[ê¸°ë²• {i+1}] {t['title']}\n{t['content'][:500]}..." for i, t in enumerate(techniques_results)])
        
        domain_hint = get_domain_hint(purpose)
        formatted_hint = format_hint_for_prompt(domain_hint)
        
        prompt = f"""ì‚¬ìš©ìê°€ "{purpose}"ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ì›í•©ë‹ˆë‹¤.

ã€ğŸ”´ í•µì‹¬: ì‚¬ìš©ì ë¸Œë ˆì¸ìŠ¤í† ë° í‚¤ì›Œë“œ (ë¹„ì¤‘ 80%)ã€‘
{keyword_str}

ã€ğŸ”µ ì°¸ê³ : ìµœì‹  íŠ¸ë Œë“œ í‚¤ì›Œë“œ (ë¹„ì¤‘ 20%)ã€‘
{", ".join(trend_keywords) if trend_keywords else "ì—†ìŒ"}

ã€ì ìš© ê°€ëŠ¥í•œ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²•ã€‘
{techniques_str}
{formatted_hint}

---
**ğŸš¨ í•„ìˆ˜ ê·œì¹™**
1. ë°˜ë“œì‹œ 3ê°œ ì•„ì´ë””ì–´ ìƒì„±
2. ë¹„ì¤‘ ì¤€ìˆ˜: ì‚¬ìš©ì í‚¤ì›Œë“œ 80% + íŠ¸ë Œë“œ 20%
3. í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€ (í†µê³„, ë¹„ìš©, ì‹œì¥ê·œëª¨ ì§€ì–´ë‚´ê¸° ê¸ˆì§€)
4. í˜„ì‹¤ì  ì‹¤í–‰ ê°€ëŠ¥: ë©°ì¹ ~ëª‡ ì£¼ ë‚´ ì‹œì‘ ê°€ëŠ¥í•œ ê²ƒë§Œ
5. ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”í•˜ë“¯ ì‘ì„± (ë”±ë”±í•œ ë³´ê³ ì„œ í˜•ì‹ X)

**ì¶œë ¥ í˜•ì‹**:
---
ì•„ì´ë””ì–´ ì œëª©: [ì œëª©]
ì£¼ì œ: [ì–´ë–¤ ë¬¸ì œ/ë‹ˆì¦ˆê°€ ìˆëŠ”ì§€ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ]
ì‹¤í–‰ ë°©í–¥: [ë¬´ì—‡ì„ ì–´ë–»ê²Œ í• ì§€ ëŒ€í™”í•˜ë“¯ ì„¤ëª…]
ê¸°ëŒ€íš¨ê³¼: [ì´ë ‡ê²Œ í•˜ë©´ ì–´ë–¤ ê²°ê³¼ê°€ ê¸°ëŒ€ë˜ëŠ”ì§€]
ê³ ë¯¼ì‚¬í•­: [ì‹¤í–‰ ì „ ê²€í† í•  ì ë“¤ì„ ì§ˆë¬¸ í˜•íƒœë¡œ. ì˜ˆ: "~ëŠ” ì¶©ë¶„í• ê¹Œ?", "~ë¥¼ ì–´ë–»ê²Œ í™•ë³´í• ê¹Œ?"]
ì ìš©ëœ ê¸°ë²•: [ê¸°ë²•ëª…]
---"""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í˜„ì‹¤ì ì¸ ê¸°íšìì…ë‹ˆë‹¤. í—ˆêµ¬ì˜ í†µê³„ë‚˜ ë¹„ìš©ì„ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ì•Šìœ¼ë©°, ì‚¬ìš©ìê°€ ê°€ì§„ ìì›ê³¼ ì—­ëŸ‰ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì‹œì‘ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            ideas_text = response.choices[0].message.content.strip()
            ideas = self._parse_ideas(ideas_text)
            
            self.session_manager.update_session(self.current_session_id, {'ideas': ideas})
            
            print(f"âœ… {len(ideas)}ê°œì˜ ì•„ì´ë””ì–´ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n")
            for i, idea in enumerate(ideas, 1):
                print(f"{'='*60}")
                print(f"ğŸ’¡ ì•„ì´ë””ì–´ {i}: {idea.get('title', 'ì œëª© ì—†ìŒ')}")
                print(f"{'='*60}")
                if idea.get('subject'):
                    print(f"\nğŸ“Œ ì£¼ì œ\n{idea.get('subject')}")
                if idea.get('direction'):
                    print(f"\nğŸ¯ ì‹¤í–‰ ë°©í–¥\n{idea.get('direction')}")
                if idea.get('expected_effect'):
                    print(f"\nâœ¨ ê¸°ëŒ€íš¨ê³¼\n{idea.get('expected_effect')}")
                if idea.get('concerns'):
                    print(f"\nğŸ¤” ê³ ë¯¼ì‚¬í•­\n{idea.get('concerns')}")
                print(f"\nğŸ”§ ì ìš© ê¸°ë²•: {idea.get('technique', 'ê¸°ë²• ì—†ìŒ')}\n")
            
            return ideas
            
        except Exception as e:
            print(f"âŒ ì•„ì´ë””ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _parse_ideas(self, ideas_text: str) -> List[Dict]:
        ideas = []
        current_idea = {}
        current_field = None
        
        for line in ideas_text.split('\n'):
            line = line.strip()
            
            if line.startswith('---'):
                if current_idea and current_idea.get('title'):
                    ideas.append(current_idea)
                current_idea = {}
                current_field = None
            elif line.startswith('ì•„ì´ë””ì–´ ì œëª©:') or line.startswith('ì œëª©:'):
                current_idea['title'] = line.split(':', 1)[1].strip()
                current_field = None
            elif line.startswith('ì£¼ì œ:'):
                current_idea['subject'] = line.split(':', 1)[1].strip()
                current_field = 'subject'
            elif line.startswith('ì‹¤í–‰ ë°©í–¥:'):
                current_idea['direction'] = line.split(':', 1)[1].strip()
                current_field = 'direction'
            elif line.startswith('ê¸°ëŒ€íš¨ê³¼:') or line.startswith('ê¸°ëŒ€ íš¨ê³¼:'):
                current_idea['expected_effect'] = line.split(':', 1)[1].strip()
                current_field = 'expected_effect'
            elif line.startswith('ê³ ë¯¼ì‚¬í•­:') or line.startswith('í™•ì¸ í•„ìš” ì‚¬í•­:') or line.startswith('í™•ì¸ í•„ìš”:'):
                current_idea['concerns'] = line.split(':', 1)[1].strip()
                current_field = 'concerns'
            elif line.startswith('ì ìš©ëœ ê¸°ë²•:') or line.startswith('ê¸°ë²•:'):
                current_idea['technique'] = line.split(':', 1)[1].strip()
                current_field = None
            elif current_field and line:
                if current_field in current_idea:
                    current_idea[current_field] += ' ' + line
                else:
                    current_idea[current_field] = line
        
        if current_idea and current_idea.get('title'):
            ideas.append(current_idea)
        
        return ideas
    
    def analyze_ideas(self, ideas: List[Dict]) -> List[Dict]:
        print("\nğŸ“Š ì•„ì´ë””ì–´ ë¶„ì„ ì¤‘...\n")
        
        for i, idea in enumerate(ideas, 1):
            print(f"{'='*60}")
            print(f"ğŸ“ˆ ì•„ì´ë””ì–´ {i} ë¶„ì„: {idea.get('title', 'ì œëª© ì—†ìŒ')}")
            print(f"{'='*60}\n")
            
            analysis = self._perform_swot_analysis(idea)
            idea['analysis'] = analysis
            idea['analysis_type'] = 'SWOT'
            
            print(f"ê°•ì  (Strengths):\n{analysis.get('strengths', 'N/A')}\n")
            print(f"ì•½ì  (Weaknesses):\n{analysis.get('weaknesses', 'N/A')}\n")
            print(f"ê¸°íšŒ (Opportunities):\n{analysis.get('opportunities', 'N/A')}\n")
            print(f"ìœ„í˜‘ (Threats):\n{analysis.get('threats', 'N/A')}\n")
        
        self.session_manager.update_session(self.current_session_id, {'ideas': ideas})
        
        print(f"{'='*60}\n")
        print("âœ… ëª¨ë“  ì•„ì´ë””ì–´ ë¶„ì„ ì™„ë£Œ!\n")
        
        return ideas
    
    def _perform_swot_analysis(self, idea: Dict) -> Dict:
        # description ìƒì„±
        desc = idea.get('description', '')
        if not desc:
            parts = []
            if idea.get('subject'):
                parts.append(idea['subject'])
            if idea.get('direction'):
                parts.append(idea['direction'])
            desc = ' '.join(parts)
        
        prompt = f"""ë‹¤ìŒ ì•„ì´ë””ì–´ì— ëŒ€í•´ SWOT ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

ì•„ì´ë””ì–´ ì œëª©: {idea.get('title', 'ì œëª© ì—†ìŒ')}
ì„¤ëª…: {desc}

**í•„ìˆ˜ í˜•ì‹** (ë°˜ë“œì‹œ 4ê°€ì§€ ëª¨ë‘ ì‘ì„±):

ê°•ì  (Strengths):
- [í•µì‹¬ ì¥ì  1ì¤„]

ì•½ì  (Weaknesses):
- [ì†”ì§í•œ ë‹¨ì  1ì¤„]

ê¸°íšŒ (Opportunities):
- [í˜„ì‹¤ì  ê¸°íšŒ 1ì¤„]

ìœ„í˜‘ (Threats):
- [êµ¬ì²´ì  ìœ„í˜‘ 1ì¤„]"""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í˜„ì‹¤ì ì¸ ê¸°íšìì…ë‹ˆë‹¤. SWOT ë¶„ì„ì€ ì§§ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
                max_tokens=500
            )
            
            analysis_text = response.choices[0].message.content.strip()
            
            swot = {'strengths': '', 'weaknesses': '', 'opportunities': '', 'threats': ''}
            current_section = None
            
            for line in analysis_text.split('\n'):
                line = line.strip()
                
                if 'ê°•ì ' in line or 'Strengths' in line.lower():
                    current_section = 'strengths'
                    if ':' in line:
                        content = line.split(':', 1)[1].strip()
                        if content:
                            swot['strengths'] = content
                elif 'ì•½ì ' in line or 'Weaknesses' in line.lower():
                    current_section = 'weaknesses'
                    if ':' in line:
                        content = line.split(':', 1)[1].strip()
                        if content:
                            swot['weaknesses'] = content
                elif 'ê¸°íšŒ' in line or 'Opportunities' in line.lower():
                    current_section = 'opportunities'
                    if ':' in line:
                        content = line.split(':', 1)[1].strip()
                        if content:
                            swot['opportunities'] = content
                elif 'ìœ„í˜‘' in line or 'Threats' in line.lower():
                    current_section = 'threats'
                    if ':' in line:
                        content = line.split(':', 1)[1].strip()
                        if content:
                            swot['threats'] = content
                elif current_section and line and line not in ['', '-', 'â€¢', '*']:
                    cleaned_line = line.lstrip('-â€¢*').strip()
                    if cleaned_line:
                        if swot[current_section]:
                            swot[current_section] += ' ' + cleaned_line
                        else:
                            swot[current_section] = cleaned_line
            
            for key in swot:
                if not swot[key]:
                    swot[key] = '(ë¶„ì„ ë°ì´í„° ì—†ìŒ)'
            
            return swot
            
        except Exception as e:
            print(f"âš ï¸  SWOT ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'strengths': 'N/A', 'weaknesses': 'N/A', 'opportunities': 'N/A', 'threats': 'N/A'}
    
    def confirm_deletion(self) -> bool:
        import time as time_module
        time_module.sleep(0.2)
        try:
            import termios
            termios.tcflush(sys.stdin, termios.TCIFLUSH)
        except:
            pass
        
        print("\n" + "="*60)
        print("ğŸ—‘ï¸  ë°ì´í„° ì‚­ì œ")
        print("="*60)
        print("\nì´ë²ˆ ì„¸ì…˜ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        print("(Q1 ëª©ì , Q2 ì›Œë°ì—…, Q3 ì—°ìƒ, ìƒì„±ëœ ì•„ì´ë””ì–´, ì„ì‹œ ë²¡í„° DB)\n")
        
        response = input("ì‚­ì œí•˜ë ¤ë©´ 'ë„¤'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
        return response == "ë„¤"
    
    def delete_session_data(self):
        if not self.current_session_id:
            print("âš ï¸  ì‚­ì œí•  ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\nğŸ—‘ï¸  ë°ì´í„° ì‚­ì œ ì¤‘...")
        
        if self.ephemeral_rag:
            self.ephemeral_rag.delete_session_data()
        
        self.session_manager.delete_session(self.current_session_id)
        
        print("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("   ì•„ì´ë””ì–´ ì˜¤ì—¼ ë° ìœ ì¶œì´ ë°©ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
        
        self.current_session_id = None
        self.ephemeral_rag = None
    
    # ============================================================
    # APIìš© ë©”ì„œë“œ (ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í˜¸ì¶œ)
    # ============================================================
    
    async def generate_ideas_for_api(self, session_id: str, purpose: str, associations: List[str]) -> List[Dict]:
        print(f"[API] ì•„ì´ë””ì–´ ìƒì„± ì‹œì‘ - ì„¸ì…˜: {session_id}")
        
        ephemeral_rag = EphemeralRAG(session_id=session_id)
        
        keywords_data = ephemeral_rag.extract_keywords_by_similarity(purpose=purpose, top_k=7)
        extracted_keywords = [kw['keyword'] for kw in keywords_data]
        print(f"[API] ì¶”ì¶œëœ í‚¤ì›Œë“œ: {extracted_keywords}")
        
        trend_keywords = await self._fetch_trend_keywords_async(purpose)
        print(f"[API] íŠ¸ë Œë“œ í‚¤ì›Œë“œ (í•„í„°ë§ ì „): {len(trend_keywords)}ê°œ")
        
        if trend_keywords:
            trend_keywords = ephemeral_rag.filter_trend_keywords(trend_keywords, top_k=10)
            print(f"[API] íŠ¸ë Œë“œ í‚¤ì›Œë“œ (í•„í„°ë§ í›„): {trend_keywords}")
        
        techniques_results = self._search_permanent_rag_for_api(query=purpose, n_results=3, ephemeral_rag=ephemeral_rag)
        
        ideas = self._generate_ideas_with_prompt(
            purpose=purpose,
            keywords=extracted_keywords,
            techniques=techniques_results,
            trend_keywords=trend_keywords
        )
        
        for idea in ideas:
            swot = self._perform_swot_analysis(idea)
            swot_text = f"""

ğŸ“Š ë¶„ì„ ê²°ê³¼:
â€¢ ê°•ì : {swot.get('strengths', 'N/A')}
â€¢ ì•½ì : {swot.get('weaknesses', 'N/A')}
â€¢ ê¸°íšŒ: {swot.get('opportunities', 'N/A')}
â€¢ ìœ„í˜‘: {swot.get('threats', 'N/A')}"""
            idea['analysis'] = swot_text
        
        print(f"[API] ì•„ì´ë””ì–´ ìƒì„± ì™„ë£Œ: {len(ideas)}ê°œ")
        return ideas
    
    async def _fetch_trend_keywords_async(self, purpose: str) -> List[str]:
        all_keywords = []
        
        if self.trend_searcher:
            try:
                naver_keywords = await self.trend_searcher.extract_trend_keywords(purpose, num_articles=5)
                if naver_keywords:
                    all_keywords.extend(naver_keywords)
                    print(f"[API] ë„¤ì´ë²„ ë‰´ìŠ¤: {len(naver_keywords)}ê°œ")
            except Exception as e:
                print(f"[API] ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        if self.duckduckgo_searcher:
            try:
                ddg_keywords = await self.duckduckgo_searcher.extract_trend_keywords(purpose, num_articles=5)
                if ddg_keywords:
                    all_keywords.extend(ddg_keywords)
                    print(f"[API] DuckDuckGo: {len(ddg_keywords)}ê°œ")
            except Exception as e:
                print(f"[API] DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        if self.datalab_searcher:
            try:
                datalab_keywords = await self.datalab_searcher.extract_trend_keywords(purpose)
                if datalab_keywords:
                    all_keywords.extend(datalab_keywords)
                    print(f"[API] ë„¤ì´ë²„ ë°ì´í„°ë©: {len(datalab_keywords)}ê°œ")
            except Exception as e:
                print(f"[API] ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return list(dict.fromkeys(all_keywords))
    
    def _search_permanent_rag_for_api(self, query: str, n_results: int = 3, ephemeral_rag: EphemeralRAG = None) -> List[Dict]:
        if not self.permanent_collection:
            return []
        
        try:
            if ephemeral_rag:
                query_embedding = ephemeral_rag.embed_text(query)
            else:
                response = self.openai_client.embeddings.create(model=self.embedding_model, input=query)
                query_embedding = response.data[0].embedding
            
            results = self.permanent_collection.query(query_embeddings=[query_embedding], n_results=n_results)
            
            techniques = []
            if results['documents'] and len(results['documents'][0]) > 0:
                for i in range(len(results['documents'][0])):
                    techniques.append({
                        'title': results['metadatas'][0][i].get('title', 'N/A'),
                        'content': results['documents'][0][i],
                    })
            return techniques
        except Exception as e:
            print(f"[API] ì˜êµ¬ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _generate_ideas_with_prompt(self, purpose: str, keywords: List[str], techniques: List[Dict], trend_keywords: List[str] = None) -> List[Dict]:
        keyword_str = ", ".join(keywords[:7])
        techniques_str = "\n\n".join([f"[ê¸°ë²• {i+1}] {t['title']}\n{t['content'][:500]}..." for i, t in enumerate(techniques)]) if techniques else "(ê¸°ë²• ì—†ìŒ)"
        
        domain_hint = get_domain_hint(purpose)
        formatted_hint = format_hint_for_prompt(domain_hint)
        
        prompt = f"""ì‚¬ìš©ìê°€ "{purpose}"ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ì›í•©ë‹ˆë‹¤.

ã€ğŸ”´ í•µì‹¬: ì‚¬ìš©ì ë¸Œë ˆì¸ìŠ¤í† ë° í‚¤ì›Œë“œ (ë¹„ì¤‘ 80%)ã€‘
{keyword_str}

ã€ğŸ”µ ì°¸ê³ : ìµœì‹  íŠ¸ë Œë“œ í‚¤ì›Œë“œ (ë¹„ì¤‘ 20%)ã€‘
{", ".join(trend_keywords) if trend_keywords else "ì—†ìŒ"}

ã€ì ìš© ê°€ëŠ¥í•œ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²•ã€‘
{techniques_str}
{formatted_hint}

---
**ğŸš¨ í•„ìˆ˜ ê·œì¹™**
1. ë°˜ë“œì‹œ 3ê°œ ì•„ì´ë””ì–´ ìƒì„±
2. ë¹„ì¤‘ ì¤€ìˆ˜: ì‚¬ìš©ì í‚¤ì›Œë“œ 80% + íŠ¸ë Œë“œ 20%
3. í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€ (í†µê³„, ë¹„ìš©, ì‹œì¥ê·œëª¨ ì§€ì–´ë‚´ê¸° ê¸ˆì§€)
4. í˜„ì‹¤ì  ì‹¤í–‰ ê°€ëŠ¥: ë©°ì¹ ~ëª‡ ì£¼ ë‚´ ì‹œì‘ ê°€ëŠ¥í•œ ê²ƒë§Œ
5. ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”í•˜ë“¯ ì‘ì„± (ë”±ë”±í•œ ë³´ê³ ì„œ í˜•ì‹ X)

**ì¶œë ¥ í˜•ì‹**:
---
ì•„ì´ë””ì–´ ì œëª©: [ì œëª©]
ì£¼ì œ: [ì–´ë–¤ ë¬¸ì œ/ë‹ˆì¦ˆê°€ ìˆëŠ”ì§€ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ]
ì‹¤í–‰ ë°©í–¥: [ë¬´ì—‡ì„ ì–´ë–»ê²Œ í• ì§€ ëŒ€í™”í•˜ë“¯ ì„¤ëª…]
ê¸°ëŒ€íš¨ê³¼: [ì´ë ‡ê²Œ í•˜ë©´ ì–´ë–¤ ê²°ê³¼ê°€ ê¸°ëŒ€ë˜ëŠ”ì§€]
ê³ ë¯¼ì‚¬í•­: [ì‹¤í–‰ ì „ ê²€í† í•  ì ë“¤ì„ ì§ˆë¬¸ í˜•íƒœë¡œ. ì˜ˆ: "~ëŠ” ì¶©ë¶„í• ê¹Œ?", "~ë¥¼ ì–´ë–»ê²Œ í™•ë³´í• ê¹Œ?"]
ì ìš©ëœ ê¸°ë²•: [ê¸°ë²•ëª…]
---"""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í˜„ì‹¤ì ì¸ ê¸°íšìì…ë‹ˆë‹¤. í—ˆêµ¬ì˜ í†µê³„ë‚˜ ë¹„ìš©ì„ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            ideas_text = response.choices[0].message.content.strip()
            return self._parse_ideas_for_api(ideas_text)
        except Exception as e:
            print(f"[API] ì•„ì´ë””ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _parse_ideas_for_api(self, ideas_text: str) -> List[Dict]:
        ideas = []
        current_idea = {}
        current_field = None
        
        for line in ideas_text.split('\n'):
            line = line.strip()
            
            if line.startswith('---'):
                if current_idea and current_idea.get('title'):
                    # description ìƒì„± (ì£¼ì œ + ì‹¤í–‰ë°©í–¥ + ê¸°ëŒ€íš¨ê³¼ + ê³ ë¯¼ì‚¬í•­)
                    desc_parts = []
                    if current_idea.get('subject'):
                        desc_parts.append(f"ğŸ“Œ ì£¼ì œ\n{current_idea['subject']}")
                    if current_idea.get('direction'):
                        desc_parts.append(f"ğŸ¯ ì‹¤í–‰ ë°©í–¥\n{current_idea['direction']}")
                    if current_idea.get('expected_effect'):
                        desc_parts.append(f"âœ¨ ê¸°ëŒ€íš¨ê³¼\n{current_idea['expected_effect']}")
                    if current_idea.get('concerns'):
                        desc_parts.append(f"ğŸ¤” ê³ ë¯¼ì‚¬í•­\n{current_idea['concerns']}")
                    if current_idea.get('technique'):
                        desc_parts.append(f"ğŸ”§ ì ìš© ê¸°ë²•: {current_idea['technique']}")
                    current_idea['description'] = '\n\n'.join(desc_parts)
                    ideas.append(current_idea)
                current_idea = {}
                current_field = None
            elif line.startswith('ì•„ì´ë””ì–´ ì œëª©:') or line.startswith('ì œëª©:'):
                current_idea['title'] = line.split(':', 1)[1].strip()
            elif line.startswith('ì£¼ì œ:'):
                current_idea['subject'] = line.split(':', 1)[1].strip()
                current_field = 'subject'
            elif line.startswith('ì‹¤í–‰ ë°©í–¥:'):
                current_idea['direction'] = line.split(':', 1)[1].strip()
                current_field = 'direction'
            elif line.startswith('ê¸°ëŒ€íš¨ê³¼:') or line.startswith('ê¸°ëŒ€ íš¨ê³¼:'):
                current_idea['expected_effect'] = line.split(':', 1)[1].strip()
                current_field = 'expected_effect'
            elif line.startswith('ê³ ë¯¼ì‚¬í•­:') or line.startswith('í™•ì¸ í•„ìš” ì‚¬í•­:') or line.startswith('í™•ì¸ í•„ìš”:'):
                current_idea['concerns'] = line.split(':', 1)[1].strip()
                current_field = 'concerns'
            elif line.startswith('ì ìš©ëœ ê¸°ë²•:') or line.startswith('ê¸°ë²•:'):
                current_idea['technique'] = line.split(':', 1)[1].strip()
                current_field = None
            elif current_field and line:
                if current_field in current_idea:
                    current_idea[current_field] += ' ' + line
                else:
                    current_idea[current_field] = line
        
        # ë§ˆì§€ë§‰ ì•„ì´ë””ì–´
        if current_idea and current_idea.get('title'):
            desc_parts = []
            if current_idea.get('subject'):
                desc_parts.append(f"ğŸ“Œ ì£¼ì œ\n{current_idea['subject']}")
            if current_idea.get('direction'):
                desc_parts.append(f"ğŸ¯ ì‹¤í–‰ ë°©í–¥\n{current_idea['direction']}")
            if current_idea.get('expected_effect'):
                desc_parts.append(f"âœ¨ ê¸°ëŒ€íš¨ê³¼\n{current_idea['expected_effect']}")
            if current_idea.get('concerns'):
                desc_parts.append(f"ğŸ¤” ê³ ë¯¼ì‚¬í•­\n{current_idea['concerns']}")
            if current_idea.get('technique'):
                desc_parts.append(f"ğŸ”§ ì ìš© ê¸°ë²•: {current_idea['technique']}")
            current_idea['description'] = '\n\n'.join(desc_parts)
            ideas.append(current_idea)
        
        return ideas
    
    def run(self):
        try:
            self.start_new_session()
            purpose = self.q1_ask_purpose()
            trend_keywords = self.fetch_trend_keywords(purpose)
            warmup_questions = self.q2_generate_warmup(purpose)
            
            while not self.q2_wait_for_confirmation():
                pass
            
            associations = self.q3_free_association(time_limit=30, min_items=10, max_items=20)
            
            print("\nğŸ” Q1ê³¼ Q3 ê°„ ìœ ì‚¬ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...\n")
            keywords = self.ephemeral_rag.extract_keywords_by_similarity(purpose, top_k=7)
            
            if trend_keywords:
                print("\nğŸ” íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©ì ì…ë ¥ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ ì¤‘...")
                trend_keywords = self.ephemeral_rag.filter_trend_keywords(trend_keywords, top_k=10)
            
            ideas = self.generate_ideas(purpose, keywords, top_k_techniques=3, trend_keywords=trend_keywords)
            
            if not ideas:
                print("âš ï¸  ì•„ì´ë””ì–´ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return
            
            ideas = self.analyze_ideas(ideas)
            
            if self.confirm_deletion():
                self.delete_session_data()
            else:
                print("\nâœ… ë°ì´í„°ê°€ ìœ ì§€ë©ë‹ˆë‹¤.")
                print(f"   ì„¸ì…˜ ID: {self.current_session_id}")
                print("   ë‚˜ì¤‘ì— /delete ëª…ë ¹ìœ¼ë¡œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")
            
            print("\n" + "="*60)
            print("ğŸ‰ ì•„ì´ë””ì–´ ìƒì„± ì™„ë£Œ!")
            print("="*60)
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            if self.confirm_deletion():
                self.delete_session_data()
        
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    generator = IdeaGenerator()
    generator.run()
