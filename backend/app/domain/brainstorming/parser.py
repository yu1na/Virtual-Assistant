"""
ë¸Œë ˆì¸ìŠ¤í† ë° ì²­í¬ íŒŒì¼ íŒŒì‹± ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ Markdown í˜•ì‹ì˜ ì²­í¬ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ 
ê°œë³„ ì²­í¬ë¡œ ë¶„ë¦¬í•˜ê³  JSON í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""
import re
import json
from pathlib import Path
from typing import List, Dict
from datetime import datetime


class ChunkParser:
    """ì²­í¬ íŒŒì¼ì„ íŒŒì‹±í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ data ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
        self.base_dir = Path(__file__).parent
        self.data_dir = self.base_dir / "data"
        self.prompts_dir = self.data_dir / "prompts"
        self.embeddings_dir = self.data_dir / "embeddings"
        
    def parse_chunks(self, file_path: str = None) -> List[Dict]:
        """
        ì²­í¬ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        
        Args:
            file_path: íŒŒì‹±í•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: data/prompts/ChunkBrainstormingTechniques.md)
            
        Returns:
            íŒŒì‹±ëœ ì²­í¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            [
                {
                    "chunk_id": "01",
                    "title": "ë§ˆì¸ë“œ ë§¤í•‘",
                    "content": "ìˆ˜í–‰ ë°©ì‹: ...",
                    "metadata": {
                        "created_at": "2025-11-17T...",
                        "word_count": 150
                    }
                },
                ...
            ]
        """
        # ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if file_path is None:
            file_path = self.prompts_dir / "ChunkBrainstormingTechniques.md"
        else:
            file_path = Path(file_path)
            
        # íŒŒì¼ ì½ê¸°
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ì²­í¬ ë¶„ë¦¬ (# [CHUNK XX] íŒ¨í„´ìœ¼ë¡œ ë¶„ë¦¬)
        # ì •ê·œì‹ ì„¤ëª…:
        # - # \[CHUNK (\d+)\]: CHUNK í—¤ë”ë¥¼ ì°¾ê³ , ìˆ«ìë¥¼ ìº¡ì²˜
        # - (?:\n|$): ì¤„ë°”ê¿ˆ ë˜ëŠ” íŒŒì¼ ë
        chunk_pattern = r'# \[CHUNK (\d+)\]\n(.*?)(?=# \[CHUNK \d+\]|$)'
        matches = re.findall(chunk_pattern, content, re.DOTALL)
        
        chunks = []
        for chunk_id, chunk_content in matches:
            # ì²­í¬ ë‚´ìš© ì •ë¦¬
            chunk_content = chunk_content.strip()
            
            # ì œëª© ì¶”ì¶œ (ì²« ë²ˆì§¸ ì¤„ ë˜ëŠ” ì²« ë²ˆì§¸ ë¬¸ë‹¨)
            lines = chunk_content.split('\n')
            title = lines[0].strip() if lines else f"ì²­í¬ {chunk_id}"
            
            # ì²­í¬ ë°ì´í„° êµ¬ì„±
            chunk_data = {
                "chunk_id": chunk_id.zfill(2),  # "1" -> "01"
                "title": title,
                "content": chunk_content,
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "word_count": len(chunk_content),
                    "char_count": len(chunk_content),
                    "source_file": file_path.name
                }
            }
            
            chunks.append(chunk_data)
        
        return chunks
    
    def save_to_json(self, chunks: List[Dict], output_filename: str = "parsed_chunks.json"):
        """
        íŒŒì‹±ëœ ì²­í¬ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            chunks: íŒŒì‹±ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
            output_filename: ì¶œë ¥ íŒŒì¼ëª… (ê¸°ë³¸ê°’: parsed_chunks.json)
        """
        output_path = self.embeddings_dir / output_filename
        
        # embeddings ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        self.embeddings_dir.mkdir(parents=True, exist_ok=True)
        
        # JSON ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(chunks, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… {len(chunks)}ê°œì˜ ì²­í¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
        return output_path
    
    def process(self, file_path: str = None, output_filename: str = "parsed_chunks.json"):
        """
        íŒŒì‹±ë¶€í„° ì €ì¥ê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        
        Args:
            file_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ
            output_filename: ì¶œë ¥ íŒŒì¼ëª…
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        print("ğŸ“„ ì²­í¬ íŒŒì¼ íŒŒì‹± ì‹œì‘...")
        chunks = self.parse_chunks(file_path)
        print(f"âœ… {len(chunks)}ê°œì˜ ì²­í¬ë¥¼ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤.")
        
        print("\nğŸ’¾ JSON íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
        output_path = self.save_to_json(chunks, output_filename)
        
        # í†µê³„ ì¶œë ¥
        print("\nğŸ“Š íŒŒì‹± ê²°ê³¼:")
        print(f"   - ì´ ì²­í¬ ìˆ˜: {len(chunks)}")
        print(f"   - í‰ê·  ê¸€ì ìˆ˜: {sum(c['metadata']['char_count'] for c in chunks) // len(chunks)}")
        print(f"   - ì €ì¥ ìœ„ì¹˜: {output_path}")
        
        return output_path


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ìš© ì½”ë“œ
if __name__ == "__main__":
    parser = ChunkParser()
    parser.process()

