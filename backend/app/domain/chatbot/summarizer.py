"""
ëŒ€í™” ìš”ì•½ ìƒì„±ê¸°

ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ìš”ì•½í•©ë‹ˆë‹¤.
- ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ
- ì£¼ìš” ì§ˆë¬¸ ë° ë‹µë³€ ì •ë¦¬
- ëŒ€í™” ë§¥ë½ íŒŒì•…
"""

import os
from typing import List
from openai import OpenAI


class Summarizer:
    """
    ëŒ€í™” ìš”ì•½ ìƒì„±ê¸°
    
    LLMì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ìš”ì•½ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = os.getenv("LLM_MODEL", "gpt-4o")
    
    def create_summary(self, messages: List[dict]) -> str:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ìš”ì•½
        
        Args:
            messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ [{"role": "user/assistant", "content": "..."}, ...]
            
        Returns:
            str: êµ¬ì¡°í™”ëœ ìš”ì•½ (Markdown)
        """
        # ëŒ€í™”ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ìš”ì•½ ìƒëµ
        if len(messages) < 5:
            return "## ìš”ì•½ ì •ë³´\n\nëŒ€í™”ê°€ ì§§ì•„ ìš”ì•½ì„ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # ëŒ€í™” ë‚´ìš© í¬ë§·íŒ…
        conversation_text = self._format_conversation(messages)
        
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸
        summary_prompt = self._get_summary_prompt(conversation_text)
        
        try:
            # LLM í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": summary_prompt}
                ],
                temperature=0.3,  # ì¼ê´€ëœ ìš”ì•½ì„ ìœ„í•´ ë‚®ì€ temperature
                max_tokens=500
            )
            
            summary = response.choices[0].message.content
            return summary
        
        except Exception as e:
            return f"## ìš”ì•½ ìƒì„± ì‹¤íŒ¨\n\nì˜¤ë¥˜: {str(e)}"
    
    def _format_conversation(self, messages: List[dict]) -> str:
        """ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        lines = []
        for i, msg in enumerate(messages, 1):
            role_icon = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
            role_name = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
            lines.append(f"[{i}] {role_icon} {role_name}: {msg['content']}")
        
        return "\n".join(lines)
    
    def _get_summary_prompt(self, conversation_text: str) -> str:
        """ìš”ì•½ ìƒì„± í”„ë¡¬í”„íŠ¸"""
        return f"""ë‹¹ì‹ ì€ ëŒ€í™” ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì—¬ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ **ë¯¸ë˜ì— ì°¸ê³ í•  ì¤‘ìš”í•œ ì •ë³´**ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

# ìš”ì•½ ê¸°ì¤€
1. **ì‚¬ìš©ì ì •ë³´**: ì´ë¦„, ì§ê¸‰, ì„ í˜¸ ìŠ¤íƒ€ì¼ ë“± (ì–¸ê¸‰ëœ ê²½ìš°ë§Œ)
2. **í•µì‹¬ ì§ˆë¬¸**: ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ ì¤‘ìš”í•œ ë‚´ìš© (ì¬ì§ˆë¬¸ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²ƒ)
3. **ì‚¬ì‹¤ ì •ë³´**: ê·œì •, ì„¤ëª…, êµ¬ì²´ì  ë‹µë³€
4. **ëŒ€í™” ë§¥ë½**: ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬, ëŒ€í™” íë¦„
5. **ì œì™¸ ëŒ€ìƒ**: ë‹¨ìˆœ ì¸ì‚¬, ì˜ë¯¸ ì—†ëŠ” ì¡ë‹´

# ì¶œë ¥ í˜•ì‹ (Markdown, ê°„ê²°í•˜ê²Œ)
```markdown
## ì‚¬ìš©ì ì •ë³´
- ì´ë¦„: [ì¶”ì¶œ or ì—†ìŒ]
- íŠ¹ì§•: [ì§ê¸‰/ì—­í• /íŠ¹ì„± or ì—†ìŒ]

## ì£¼ìš” ì§ˆë¬¸ ë° ë‹µë³€
1. [ì£¼ì œ] (ëŒ€í™” ë²ˆí˜¸)
   - ì§ˆë¬¸: [1-2ë¬¸ì¥ ìš”ì•½]
   - ë‹µë³€: [í•µì‹¬ë§Œ 1-2ë¬¸ì¥]

(3ê°œ ì´ë‚´ë¡œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒë§Œ)

## ëŒ€í™” ë§¥ë½
- [ì‚¬ìš©ì ê´€ì‹¬ì‚¬/íŒ¨í„´ 2-3ë¬¸ì¥]

## í‚¤ì›Œë“œ
[ê´€ë ¨ í‚¤ì›Œë“œ 5ê°œ ì´ë‚´]
```

# ëŒ€í™” ë‚´ì—­
{conversation_text}

**ì¤‘ìš”:** ë‹¨ìˆœ ì¸ì‚¬ë‚˜ ì˜ë¯¸ ì—†ëŠ” ë‚´ìš©ì€ ìƒëµí•˜ê³ , **ë‚˜ì¤‘ì— ì°¸ê³ í•  ê°€ì¹˜ê°€ ìˆëŠ” ì •ë³´ë§Œ** í¬í•¨í•˜ì„¸ìš”.
ìš”ì•½ì€ 200 í† í° ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""
    
    def update_summary(self, existing_summary: str, new_messages: List[dict]) -> str:
        """
        ê¸°ì¡´ ìš”ì•½ì— ìƒˆë¡œìš´ ëŒ€í™” ì¶”ê°€ (ëˆ„ì  ìš”ì•½)
        
        Args:
            existing_summary: ê¸°ì¡´ ìš”ì•½
            new_messages: ìƒˆë¡œìš´ ë©”ì‹œì§€ë“¤
            
        Returns:
            str: ì—…ë°ì´íŠ¸ëœ ìš”ì•½
        """
        # ìƒˆë¡œìš´ ëŒ€í™” í¬ë§·íŒ…
        new_conversation = self._format_conversation(new_messages)
        
        # ì—…ë°ì´íŠ¸ í”„ë¡¬í”„íŠ¸
        update_prompt = f"""ë‹¹ì‹ ì€ ëŒ€í™” ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ê¸°ì¡´ ìš”ì•½
{existing_summary}

# ìƒˆë¡œìš´ ëŒ€í™”
{new_conversation}

ìœ„ ìƒˆë¡œìš´ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ **ê¸°ì¡´ ìš”ì•½ì„ ì—…ë°ì´íŠ¸**í•˜ì„¸ìš”.

ì—…ë°ì´íŠ¸ ê·œì¹™:
- ìƒˆë¡œìš´ ì¤‘ìš” ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
- ì¤‘ë³µëœ ë‚´ìš©ì€ í†µí•©
- ëœ ì¤‘ìš”í•œ ë‚´ìš©ì€ ì œê±°
- ì „ì²´ ê¸¸ì´ëŠ” 200 í† í° ì´ë‚´ ìœ ì§€

ë™ì¼í•œ Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."""
        
        try:
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": update_prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            return response.choices[0].message.content
        
        except Exception as e:
            # ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ìš”ì•½ ìœ ì§€
            return existing_summary

