"""
Daily Report Builder

FSM ê²°ê³¼ë¥¼ CanonicalReportë¡œ ë³€í™˜

Author: AI Assistant
Created: 2025-11-18
"""
from typing import List, Dict, Any, Set, Optional
from datetime import date
import hashlib
import re
import numpy as np
import openai
from functools import lru_cache

from app.domain.report.core.canonical_models import (
    CanonicalReport,
    CanonicalDaily,
    DetailTask
)
from app.core.config import settings

# ë³´ê³ ì„œ ownerëŠ” ìƒìˆ˜ë¡œ ì‚¬ìš© (ì‹¤ì œ ì‚¬ìš©ì ì´ë¦„ê³¼ ë¶„ë¦¬)
REPORT_OWNER = settings.REPORT_WORKSPACE_OWNER

EMBEDDING_MODEL = "text-embedding-3-large"
EMBEDDING_DIM = 3072


@lru_cache(maxsize=1000)
def get_embedding(text: str) -> np.ndarray:
    """
    í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì ìš©)
    
    Args:
        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        
    Returns:
        ì„ë² ë”© ë²¡í„° (numpy array)
    """
    try:
        client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
        response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text.strip()
        )
        return np.array(response.data[0].embedding)
    except Exception as e:
        print(f"[ERROR] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ì‹œ ë¹ˆ ë²¡í„° ë°˜í™˜
        return np.zeros(EMBEDDING_DIM)


def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """
    ë‘ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    
    Args:
        vec1: ì²« ë²ˆì§¸ ë²¡í„°
        vec2: ë‘ ë²ˆì§¸ ë²¡í„°
        
    Returns:
        ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0.0 ~ 1.0)
    """
    # ë²¡í„° í¬ê¸°ê°€ 0ì¸ ê²½ìš° ì²˜ë¦¬
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarity = np.dot(vec1, vec2) / (norm1 * norm2)
    
    # -1 ~ 1 ë²”ìœ„ë¥¼ 0 ~ 1ë¡œ ë³€í™˜
    return float((similarity + 1) / 2)


def calculate_semantic_similarity(text1: str, text2: str) -> float:
    """
    ë‘ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° (ì„ë² ë”© ê¸°ë°˜)
    
    Args:
        text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸
        text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸
        
    Returns:
        ì˜ë¯¸ì  ìœ ì‚¬ë„ (0.0 ~ 1.0)
    """
    if not text1.strip() or not text2.strip():
        return 0.0
    
    # ì„ë² ë”© ìƒì„±
    emb1 = get_embedding(text1)
    emb2 = get_embedding(text2)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    return cosine_similarity(emb1, emb2)


def calculate_text_similarity(text1: str, text2: str) -> float:
    """
    ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (Jaccard similarity) - Fallbackìš©
    
    Args:
        text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸
        text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸
        
    Returns:
        ìœ ì‚¬ë„ (0.0 ~ 1.0)
    """
    # ì •ê·œí™”: ì†Œë¬¸ì, ê³µë°± ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°
    def normalize(text: str) -> Set[str]:
        text = text.lower()
        text = re.sub(r'[^\w\sê°€-í£]', '', text)
        # 2ê¸€ì ì´ìƒì˜ ë‹¨ì–´ë§Œ ì¶”ì¶œ (ì¡°ì‚¬ ì œê±°)
        words = [w for w in text.split() if len(w) >= 2]
        return set(words)
    
    set1 = normalize(text1)
    set2 = normalize(text2)
    
    if not set1 or not set2:
        return 0.0
    
    intersection = set1 & set2
    union = set1 | set2
    
    return len(intersection) / len(union) if union else 0.0


def find_completed_main_tasks(
    main_tasks: List[Dict[str, Any]],
    time_tasks: List[Dict[str, Any]],
    similarity_threshold: float = 0.75
) -> Set[int]:
    """
    ì‹¤ì œ ìˆ˜í–‰ëœ main_tasks ì¸ë±ìŠ¤ ì°¾ê¸° (ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ì  ìœ ì‚¬ë„)
    
    Args:
        main_tasks: ì˜ˆì •ëœ ì—…ë¬´ ëª©ë¡
        time_tasks: ì‹¤ì œ ìˆ˜í–‰í•œ ì—…ë¬´ ëª©ë¡
        similarity_threshold: ì˜ë¯¸ì  ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ 0.75 = 75%)
        
    Returns:
        ì‹¤ì œ ìˆ˜í–‰ëœ main_taskì˜ ì¸ë±ìŠ¤ Set
    """
    completed_indices = set()
    
    print("\nğŸ” [ì—…ë¬´ ë§¤ì¹­ ì‹œì‘] ì˜ˆì • ì—…ë¬´ì™€ ì‹¤ì œ ì—…ë¬´ ë¹„êµ (ì„ë² ë”© ê¸°ë°˜)")
    print(f"   - ì˜ˆì • ì—…ë¬´: {len(main_tasks)}ê°œ")
    print(f"   - ì‹¤ì œ ì—…ë¬´: {len(time_tasks)}ê°œ")
    print(f"   - ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold:.2f} (75%)")
    
    for main_idx, main_task in enumerate(main_tasks):
        main_title = main_task.get("title", "")
        main_desc = main_task.get("description", "")
        
        # main_taskì˜ í•µì‹¬ í…ìŠ¤íŠ¸ (title ìš°ì„ , description ë³´ì¡°)
        main_text = main_title
        if main_desc and main_desc.strip():
            main_text = f"{main_title} {main_desc}"
        
        best_similarity = 0.0
        best_match_title = ""
        
        for time_task in time_tasks:
            time_title = time_task.get("title", "")
            time_desc = time_task.get("description", "")
            
            # time_taskì˜ í•µì‹¬ í…ìŠ¤íŠ¸ (title ìš°ì„ )
            time_text = time_title
            if time_desc and time_desc.strip():
                time_text = f"{time_title} {time_desc}"
            
            # ğŸ”¥ ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°
            try:
                semantic_similarity = calculate_semantic_similarity(main_text, time_text)
                
                # ìµœê³  ìœ ì‚¬ë„ ì¶”ì 
                if semantic_similarity > best_similarity:
                    best_similarity = semantic_similarity
                    best_match_title = time_title
                
                # ë§¤ì¹­ ì¡°ê±´: ì˜ë¯¸ì  ìœ ì‚¬ë„ê°€ ì„ê³„ê°’(0.75) ì´ìƒ
                if semantic_similarity >= similarity_threshold:
                    completed_indices.add(main_idx)
                    print(f"   âœ… ë§¤ì¹­ ì„±ê³µ: '{main_title}' â†” '{time_title}'")
                    print(f"      â””â”€ ì˜ë¯¸ì  ìœ ì‚¬ë„: {semantic_similarity:.3f}")
                    break
                    
            except Exception as e:
                print(f"   âš ï¸ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
                # ì˜¤ë¥˜ ë°œìƒì‹œ fallbackìœ¼ë¡œ Jaccard ìœ ì‚¬ë„ ì‚¬ìš©
                fallback_similarity = calculate_text_similarity(main_text, time_text)
                if fallback_similarity >= 0.5:  # fallback threshold
                    completed_indices.add(main_idx)
                    print(f"   âœ… ë§¤ì¹­ (fallback): '{main_title}' â†” '{time_title}' ({fallback_similarity:.2f})")
                    break
        
        # ë§¤ì¹­ ì‹¤íŒ¨ì‹œ ë¡œê·¸
        if main_idx not in completed_indices:
            print(f"   âŒ ë¯¸ì¢…ê²°: '{main_title}'")
            if best_match_title:
                print(f"      â””â”€ ê°€ì¥ ìœ ì‚¬í•œ ì—…ë¬´: '{best_match_title}' (ìœ ì‚¬ë„: {best_similarity:.3f}, ì„ê³„ê°’ ë¯¸ë‹¬)")
    
    print(f"\nğŸ“Š [ë§¤ì¹­ ê²°ê³¼] ì™„ë£Œëœ ì—…ë¬´: {len(completed_indices)}/{len(main_tasks)}ê°œ")
    print(f"   - ë¯¸ì¢…ê²° ì—…ë¬´: {len(main_tasks) - len(completed_indices)}ê°œ\n")
    
    return completed_indices


def build_daily_report(
    owner: str,  # ì‹¤ì œ ì‚¬ìš©ì ì´ë¦„ (display_nameìš©, ë” ì´ìƒ CanonicalReport.ownerì— ì €ì¥ ì•ˆ í•¨)
    target_date: date,
    main_tasks: List[Dict[str, Any]],
    time_tasks: List[Dict[str, Any]],
    issues: List[Dict[str, Any]] = None,
    plans: List[Dict[str, Any]] = None,
    display_name: Optional[str] = None  # HTML ë³´ê³ ì„œì— í‘œì‹œí•  ì´ë¦„
) -> CanonicalReport:
    """
    ì¼ì¼ë³´ê³ ì„œ ìƒì„±
    
    ì‹¤ë¬´ ê¸°ì¤€:
    - main_tasks = ì•„ì¹¨ì— ì„ íƒí•œ "ì˜ˆì •" ì—…ë¬´
    - time_tasks = FSMì—ì„œ ì…ë ¥í•œ "ì‹¤ì œ ìˆ˜í–‰" ì—…ë¬´
    - issues = FSMì—ì„œ ì…ë ¥í•œ "ì´ìŠˆ ì‚¬í•­"
    - plans = FSMì—ì„œ ì…ë ¥í•œ "ìµì¼ ì—…ë¬´ ê³„íš"
    - ì‹¤ì œ ìˆ˜í–‰ë˜ì§€ ì•Šì€ main_tasks â†’ unresolved (ë¯¸ì¢…ê²° ì—…ë¬´)
    
    Args:
        owner: ì‘ì„±ì (deprecated, í˜¸í™˜ì„± ìœ ì§€ìš©)
        target_date: ë‚ ì§œ
        main_tasks: ê¸ˆì¼ ì§„í–‰ ì—…ë¬´ (ì˜ˆì •, TodayPlanì—ì„œ ì„ íƒ)
        time_tasks: ì‹œê°„ëŒ€ë³„ ì„¸ë¶€ì—…ë¬´ (ì‹¤ì œ ìˆ˜í–‰, FSM ì…ë ¥)
        issues: ì´ìŠˆ ì‚¬í•­ (FSM ì…ë ¥, optional)
        plans: ìµì¼ ì—…ë¬´ ê³„íš (FSM ì…ë ¥, optional)
        display_name: HTML ë³´ê³ ì„œì— í‘œì‹œí•  ì´ë¦„ (ì„ íƒ, ì—†ìœ¼ë©´ owner ì‚¬ìš©)
        
    Returns:
        CanonicalReport ê°ì²´ (ownerëŠ” ìƒìˆ˜ë¡œ ì„¤ì •ë¨)
    """
    if issues is None:
        issues = []
    if plans is None:
        plans = []
    # report_id ìƒì„± (deterministic, ìƒìˆ˜ owner ì‚¬ìš©)
    report_id = generate_report_id(REPORT_OWNER, target_date)
    
    # display_name ê²°ì • (HTML ë³´ê³ ì„œìš©)
    actual_display_name = display_name or owner
    
    # ğŸ”¥ ì‹¤ì œ ìˆ˜í–‰ëœ main_task ì¸ë±ìŠ¤ ì°¾ê¸° (fuzzy matching)
    completed_main_indices = find_completed_main_tasks(main_tasks, time_tasks)
    
    # ğŸ”¥ ë¯¸ì¢…ê²° ì—…ë¬´ = main_tasks ì¤‘ ìˆ˜í–‰ë˜ì§€ ì•Šì€ ê²ƒ
    unresolved_tasks = [
        main_tasks[i].get("title", "")
        for i in range(len(main_tasks))
        if i not in completed_main_indices
    ]
    
    # ğŸ”¥ íŠ¹ì´ì‚¬í•­ = FSM ì´ìŠˆì‚¬í•­ (ë¯¸ì¢…ê²° ì—…ë¬´ì™€ ë¶„ë¦¬!)
    special_notes = []
    for issue in issues:
        description = issue.get("description", "")
        if description and description.strip():
            special_notes.append(description.strip())
    
    # ğŸ”¥ plans = ê¸ˆì¼ ì˜ˆì • ì—…ë¬´ (main_tasks) - ì›ë˜ ì„¤ê³„ëŒ€ë¡œ ìœ ì§€
    planned_tasks = [task.get("title", "") for task in main_tasks if task.get("title")]
    
    # ğŸ”¥ next_day_plans = FSM ìµì¼ ì—…ë¬´ ê³„íš (ë³„ë„ë¡œ metadataì— ì €ì¥)
    next_day_plans = []
    for plan in plans:
        title = plan.get("title", "")
        if title and title.strip():
            next_day_plans.append(title.strip())
    
    # detail_tasks = time_tasksë§Œ (ì‹¤ì œ ì™„ë£Œ ì—…ë¬´)
    detail_tasks = []
    for i, task_dict in enumerate(time_tasks):
        time_range = task_dict.get("time_range", "")
        time_start, time_end = None, None
        
        if "~" in time_range:
            parts = time_range.split("~")
            if len(parts) >= 2:
                time_start = parts[0].strip()
                time_end = parts[1].strip()
        
        task_text = task_dict.get("description", "") or task_dict.get("title", "")
        note = f"ì¹´í…Œê³ ë¦¬: {task_dict.get('category', '')}"
        
        if task_text:
            detail_tasks.append(DetailTask(
                time_start=time_start,
                time_end=time_end,
                text=task_text,
                note=note
            ))
    
    # todo_tasks = planned_tasks (ê¸ˆì¼ ì˜ˆì • ì—…ë¬´)
    todo_tasks = [task.get("title", "") for task in main_tasks if task.get("title")]
    
    # ë¡œê·¸ ì¶œë ¥
    print(f"\nğŸ“Š ì¼ì¼ë³´ê³ ì„œ ìƒì„± ìš”ì•½:")
    print(f"  - ê¸ˆì¼ ì˜ˆì • ì—…ë¬´: {len(main_tasks)}ê°œ")
    print(f"  - ì‹¤ì œ ì™„ë£Œ(detail_tasks): {len(detail_tasks)}ê°œ")
    print(f"  - íŠ¹ì´ì‚¬í•­: {len(special_notes)}ê°œ")
    print(f"  - ë¯¸ì¢…ê²° ì—…ë¬´: {len(unresolved_tasks)}ê°œ")
    print(f"  - ìµì¼ ê³„íš(next_day_plans): {len(next_day_plans)}ê°œ")
    if special_notes:
        print(f"  - íŠ¹ì´ì‚¬í•­ ë‚´ìš©: {', '.join(special_notes)}")
    if unresolved_tasks:
        print(f"  - ë¯¸ì¢…ê²° ëª©ë¡: {', '.join(unresolved_tasks)}")
    
    # ìƒˆ Canonical êµ¬ì¡°ë¡œ ìƒì„±
    notes_text = "\n".join(special_notes) if special_notes else ""
    summary_text = notes_text  # íŠ¹ì´ì‚¬í•­ì„ summaryë¡œë„ ì‚¬ìš©
    canonical_daily = CanonicalDaily(
        header={
            "ì‘ì„±ì¼ì": target_date.isoformat(),
            "ì„±ëª…": actual_display_name  # HTML ë³´ê³ ì„œì— í‘œì‹œí•  ì´ë¦„
        },
        todo_tasks=todo_tasks,
        detail_tasks=detail_tasks,
        pending=unresolved_tasks,
        plans=next_day_plans,
        notes=notes_text,
        summary=summary_text
    )
    
    return CanonicalReport(
        report_id=report_id,
        report_type="daily",
        owner=REPORT_OWNER,  # ìƒìˆ˜ owner ì‚¬ìš© (ì‹¤ì œ ì‚¬ìš©ì ì´ë¦„ê³¼ ë¶„ë¦¬)
        period_start=target_date,
        period_end=target_date,
        daily=canonical_daily
    )


def generate_report_id(owner: str, target_date: date) -> str:
    """
    ë³´ê³ ì„œ ID ìƒì„± (deterministic)
    
    Args:
        owner: ì‘ì„±ì (ìƒìˆ˜ owner ì‚¬ìš©)
        target_date: ë‚ ì§œ
        
    Returns:
        ë³´ê³ ì„œ ID
    """
    key = f"daily_{owner}_{target_date.isoformat()}"
    hash_obj = hashlib.sha256(key.encode('utf-8'))
    return hash_obj.hexdigest()[:32]

